# import dataset.transformsHDLayout as T
import dataset.data_augment as T
from pathlib import Path
from PIL import Image
import os, json
from torch.utils.data.dataset import Dataset
import torch

class HDLayoutDataset(Dataset):
    def __init__(self, img_folder, json_file, transforms, num_queries, expand_factor=1):
        # dataload
        self.img_folder = img_folder
        self.json_folder = json_file
        self.block_bbox_path = os.path.join(self.json_folder, 'block')
        self.line_bbox_path = os.path.join(self.json_folder, 'line1')
        self.char_bezier_path = os.path.join(self.json_folder, 'line2')
        # transforms
        self._transforms = transforms
        self.expand_factor = expand_factor # 保存扩充倍数
        # data
        self.data = []
        self.img_path = []
        for json_file in os.listdir(self.char_bezier_path):
            total_block_path = os.path.join(self.block_bbox_path, json_file)
            total_line1_path = os.path.join(self.line_bbox_path, json_file)
            total_line2_path = os.path.join(self.char_bezier_path, json_file)
            total_img_path = os.path.join(self.img_folder, json_file.replace('.json', '.jpg'))
            # load json
            try:
                with open(total_block_path, 'r') as file:
                    block_data = json.load(file)
                with open(total_line1_path, 'r') as file:
                    line1_data = json.load(file)
                with open(total_line2_path, 'r') as file:
                    line2_data = json.load(file)
            except:
                print(f'{json_file} json file error.')
                continue
            
            h, w = float(line2_data['imageHeight']), float(line2_data['imageWidth'])
            char_bezier, line_bbox, block_bbox = self.load_json(line2_data, line1_data, block_data, num_queries)
            if not (char_bezier != [] and line_bbox != [] and block_bbox != []):
                print(f'{json_file} json file error. char_bezier:{len(char_bezier)}, {len(line_bbox)}, {len(block_bbox)}')
                continue
            
            target = {
                'char_bezier': char_bezier,
                'line_bbox': line_bbox,
                'block_bbox': block_bbox,
                # 'orig_size': [h, w],
                'orig_size': torch.tensor([h, w]),
            }
            # load image
            img = Image.open(total_img_path).convert('RGB')
            
            # samples = {
            #     'img': img,
            #     'block_bbox': target['block_bbox'],
            # }
            # samples_block_bbox = target['block_bbox']
            # _ = target.pop('block_bbox')
            labels = {
                    'char_bezier_labels': torch.zeros((len(char_bezier),), dtype=torch.int64),
                    'line_bbox_labels': torch.zeros((len(line_bbox),), dtype=torch.int64),
                    'block_bbox_labels': torch.zeros((len(block_bbox),), dtype=torch.int64),
                }
            target.update(labels)
            self.data.append((img, target))
            self.img_path.append(total_img_path)

    def __len__(self):
        return len(self.data) * self.expand_factor

    def __getitem__(self, idx):
        # 映射回原始数据索引 (例如 idx=1005 -> real_idx=5)
        real_idx = idx % len(self.data)
        
        img, target = self.data[real_idx]
        
        # 深拷贝 target，防止多个 worker 同时修改同一个引用
        target = target.copy() 
        
        # 这里的 transforms 包含 Random 操作
        # 因为每次调用 __getitem__ 都是独立的，所以即使是同一张图，
        # 在 idx=5 和 idx=1005 时会得到不同的增强效果（不同的裁剪、颜色等）
        if self._transforms is not None:
            img, target = self._transforms(img, target)
            
        return img, target, self.img_path[real_idx]
    
    def load_json(self, line2_data, line1_data, block_data, num_queries):
        # num_queries = [num_queries[i] * num_queries[i-1] for i in range(1, len(num_queries))]
        # 存储结构
        char_bezier, line_bbox, block_bbox = [], [], []
        # 标记哪些line1、block已经被加载
        drawn_line1 = set()
        drawn_block = set()
        # 加载对应的line2
        for line2_shape in line2_data['shapes']:
            line1_label = line2_shape.get('bbox_label')
            if line1_label is not None:
                if len(line2_shape['points']) < 16:
                    print('line2data num error.')
                    continue
                if line1_label not in drawn_line1:
                    # 加载对应的line1
                    for line1_shape in line1_data['shapes']:
                        if line1_shape['label'] == line1_label:
                            block_label = line1_shape.get('region_label')
                            if block_label is not None and len(line_bbox) < num_queries[-2]:
                                if len(line1_shape['points']) < 2:
                                    print('line1data num error')
                                    continue
                                if block_label not in drawn_block:
                                    # 加载对应的block
                                    if len(drawn_block) != 0:
                                        continue
                                    for block_shape in block_data['shapes']:
                                        if block_shape['label'] == block_label and len(block_bbox) < num_queries[-3]:
                                            drawn_block.add(block_label)
                                            drawn_line1.add(line1_label)
                                            block_bbox.append(block_shape['points'][:2])
                                            line_bbox.append(line1_shape['points'][:2])
                                            char_bezier.append(line2_shape['points'][:16])
                                else:
                                    drawn_line1.add(line1_label)
                                    line_bbox.append(line1_shape['points'][:2])
                                    char_bezier.append(line2_shape['points'][:16])
                else:
                    char_bezier.append(line2_shape['points'][:16])

        return char_bezier, line_bbox, block_bbox
    
# def HDLTransforms(image_set):
#     normalize = T.Compose([
#         T.ToTensor(),
#         T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
#     ])
    
#     scales = [512]  # Since the image is 512x512, we can only resize it to this scale
    
#     if image_set == 'train':
#         return T.Compose([
#             T.RandomHorizontalFlip(),
#             # T.RandomMove(),
#             normalize,
#         ])
#     else:
#         return normalize
#     return normalize

def make_hdlayout_transforms(image_set):
    normalize = T.Compose([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    if image_set == 'train':
        return T.Compose([
            # 1. 随机平移 (新增)
            # T.RandomMove(max_shift_ratio=0.1, p=0.3),
            
            # 2. 随机翻转
            T.RandomHorizontalFlip(p=0.5),
            
            T.RandomResize([1024], max_size=1333),
            # 3. 混合增强策略 (Scale Jittering):
            # 50% 概率：单纯多尺度 Resize
            # 50% 概率：随机剪裁 + 多尺度 Resize (这能极大地增加数据多样性)
            # T.RandomSelect(
            #     T.RandomResize([1024], max_size=1333),
            #     T.Compose([
            #         T.RandomCrop(min_scale=0.6, max_scale=1.0), # (新增)
            #         T.RandomResize([1024], max_size=1333),
            #     ])
            # ),
            
            # 4. 色彩抖动
            T.ColorJitter(p=0.6),
            
            # 5. 归一化
            normalize,
        ])
    
    if image_set == 'val':
        return T.Compose([
            T.RandomResize([1024], max_size=1333),
            normalize,
        ])

    return normalize

def buildDataset(image_set, args):
    root = Path(args.dataset_path)
    assert root.exists(), f'provided dataset path {root} does not exist'
    PATHS = {
        "train": (root / "train" / "images", root / "train" / "jsons" ),
        "val": (root / "val" / "images", root / "val" / "jsons" ),
    }

    img_folder, ann_file = PATHS[image_set]
    dataset = HDLayoutDataset(
        img_folder, 
        ann_file, 
        transforms=make_hdlayout_transforms(image_set), 
        num_queries=args.num_queries,
        expand_factor=1 if image_set=='train' else 1
    )
    return dataset